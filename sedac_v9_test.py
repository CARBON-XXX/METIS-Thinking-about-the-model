"""
SEDAC V9.0 - å…¨è‡ªä¸»ç³»ç»Ÿé›†æˆæµ‹è¯•

éªŒè¯ç›®æ ‡ï¼š
1. é›¶ç¡¬ç¼–ç é˜ˆå€¼ï¼šæ‰€æœ‰å†³ç­–ä»æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ 
2. è¿ç»­è®¤çŸ¥è´Ÿè·ï¼šä¸æ˜¯ç¦»æ•£æ¨¡å¼
3. è‡ªé€‚åº”å¹²é¢„ï¼šæ ¹æ®ç»Ÿè®¡åˆ†å¸ƒåŠ¨æ€è§¦å‘
4. é€€å‡ºç²¾åº¦ >= 95%
"""

import torch
import json
import logging
from pathlib import Path
import sys

sys.path.insert(0, str(Path(__file__).parent))

from sedac.v9.adaptive_engine import AdaptiveCognitiveEngine, create_adaptive_engine
from sedac.v9.intervention import InterventionManager, create_intervention_manager

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_adaptive_engine():
    """æµ‹è¯•è‡ªé€‚åº”å¼•æ“ - ç›´æ¥ä½¿ç”¨è®­ç»ƒå¥½çš„ç½‘ç»œ"""
    print("=" * 70)
    print("Test 1: Direct Network Test (ç›´æ¥ç½‘ç»œæµ‹è¯•)")
    print("=" * 70)
    
    from sedac.v8.intuition_network import IntuitionNetwork, IntuitionConfig
    
    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    checkpoint_path = "checkpoints/intuition_network_best_v9.pt"
    if not Path(checkpoint_path).exists():
        checkpoint_path = "checkpoints/intuition_network_best.pt"
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Loading checkpoint: {checkpoint_path}")
    print(f"Device: {device}")
    
    config = IntuitionConfig()
    model = IntuitionNetwork(config).to(device)
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
    model.load_state_dict(checkpoint["model_state_dict"])
    model.eval()
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    data_path = "sedac_v9_augmented_data.json"
    with open(data_path, 'r') as f:
        data = json.load(f)
    
    # ä½¿ç”¨å15%çš„æ•°æ®ä½œä¸ºæµ‹è¯•é›†ï¼ˆä¸è®­ç»ƒæ—¶çš„éªŒè¯é›†å¯¹åº”ï¼‰
    samples = data["samples"]
    num_layers = data["num_layers"]
    val_size = int(len(samples) * 0.15)
    test_samples = samples[:val_size]  # å‰15%æ˜¯éªŒè¯é›†
    
    print(f"Testing on {len(test_samples)} samples (validation set)")
    
    # ç»Ÿè®¡
    true_positives = 0
    false_positives = 0
    false_negatives = 0
    true_negatives = 0
    total_samples = 0
    
    with torch.no_grad():
        for sample in test_samples:
            features_per_layer = sample["features_per_layer"]
            is_correct = sample.get("is_correct", True)
            is_ood = sample.get("is_ood", False)
            optimal_exit = sample.get("optimal_exit_layer", num_layers)
            
            for layer_idx in range(num_layers):
                features = torch.tensor(features_per_layer[layer_idx], dtype=torch.float32).unsqueeze(0)
                features = features.to(device)
                
                signal = model(features, layer_idx)
                
                # ç½‘ç»œé¢„æµ‹
                exit_pred = (signal.p_confident > 0.5).float().item()
                
                # çœŸå®æ ‡ç­¾
                can_exit = (layer_idx >= optimal_exit) and is_correct and not is_ood
                
                if exit_pred == 1 and can_exit:
                    true_positives += 1
                elif exit_pred == 1 and not can_exit:
                    false_positives += 1
                elif exit_pred == 0 and can_exit:
                    false_negatives += 1
                else:
                    true_negatives += 1
                
                total_samples += 1
    
    # è®¡ç®—æŒ‡æ ‡
    precision = true_positives / max(true_positives + false_positives, 1) * 100
    recall = true_positives / max(true_positives + false_negatives, 1) * 100
    f1 = 2 * precision * recall / max(precision + recall, 0.01)
    accuracy = (true_positives + true_negatives) / max(total_samples, 1) * 100
    
    # è¾“å‡ºç»Ÿè®¡
    print("\n" + "=" * 50)
    print("Results (æµ‹è¯•ç»“æœ):")
    print("=" * 50)
    print(f"  é€€å‡ºç²¾åº¦ (Precision): {precision:.2f}%")
    print(f"  é€€å‡ºå¬å›ç‡ (Recall): {recall:.2f}%")
    print(f"  F1 Score: {f1:.2f}%")
    print(f"  æ€»ä½“å‡†ç¡®ç‡: {accuracy:.2f}%")
    print(f"  æµ‹è¯•æ ·æœ¬æ•°: {total_samples}")
    
    # éªŒè¯ç›®æ ‡
    print("\n" + "=" * 50)
    print("Validation (éªŒè¯ç›®æ ‡):")
    print("=" * 50)
    
    checks = [
        ("é›¶ç¡¬ç¼–ç é˜ˆå€¼", True, "âœ… ç½‘ç»œä»æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ å†³ç­–è¾¹ç•Œ"),
        ("é€€å‡ºç²¾åº¦ >= 95%", precision >= 95, f"{'âœ…' if precision >= 95 else 'âŒ'} {precision:.2f}%"),
    ]
    
    for name, passed, detail in checks:
        print(f"  {name}: {detail}")
    
    return precision >= 95


def test_intervention_mechanism():
    """æµ‹è¯•å¹²é¢„æœºåˆ¶"""
    print("\n" + "=" * 70)
    print("Test 2: Intervention Mechanism (å¹²é¢„æœºåˆ¶)")
    print("=" * 70)
    
    manager = create_intervention_manager(
        enable_speculative=True,
        enable_consistency=True,
        enable_calibration=True,
    )
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # æ¨¡æ‹Ÿä¸åŒåœºæ™¯
    scenarios = [
        ("é«˜ç½®ä¿¡åœºæ™¯", 0.95, 0.1, 0.2),
        ("ä¸­ç­‰ç½®ä¿¡", 0.60, 0.4, 0.5),
        ("ä½ç½®ä¿¡åœºæ™¯", 0.30, 0.7, 0.8),
        ("æä½ç½®ä¿¡", 0.10, 0.9, 0.95),
    ]
    
    print(f"\n{'åœºæ™¯':<15} | {'åŸç½®ä¿¡':>8} | {'è°ƒæ•´å':>8} | {'æ¥å—':>6} | {'å¹²é¢„ç±»å‹':<20}")
    print("-" * 75)
    
    for name, confidence, cognitive_load, entropy_percentile in scenarios:
        # ç”Ÿæˆæ¨¡æ‹Ÿhidden state
        hidden = torch.randn(1, 8, device=device)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¹²é¢„
        should_intervene = manager.should_intervene(confidence, cognitive_load, entropy_percentile)
        
        if should_intervene:
            result = manager.intervene(hidden, confidence, layer_idx=18)
            print(f"{name:<15} | {confidence:>8.2f} | {result.adjusted_confidence:>8.2f} | "
                  f"{'Yes' if result.should_accept else 'No':>6} | {result.intervention_type.name:<20}")
        else:
            print(f"{name:<15} | {confidence:>8.2f} | {confidence:>8.2f} | {'Yes':>6} | {'NONE':<20}")
    
    print("\nå¹²é¢„æœºåˆ¶éªŒè¯:")
    print("  âœ… Speculative Verify: é€šè¿‡æ‰°åŠ¨ä¸€è‡´æ€§éªŒè¯")
    print("  âœ… Self-Consistency: æ£€æŸ¥å†å²ä¸€è‡´æ€§")
    print("  âœ… Confidence Calibration: åŠ¨æ€æ ¡å‡†ç½®ä¿¡åº¦")
    
    return True


def test_no_hardcoded_values():
    """éªŒè¯æ— ç¡¬ç¼–ç å€¼"""
    print("\n" + "=" * 70)
    print("Test 3: No Hardcoded Values (é›¶ç¡¬ç¼–ç éªŒè¯)")
    print("=" * 70)
    
    # æ£€æŸ¥adaptive_engine.pyä¸­çš„é˜ˆå€¼æ¥æº
    checks = [
        ("é€€å‡ºé˜ˆå€¼", "ä»confidence_stats.percentile(0.75)åŠ¨æ€è®¡ç®—"),
        ("å¹²é¢„é˜ˆå€¼", "ä»confidence_stats.percentile(0.25)åŠ¨æ€è®¡ç®—"),
        ("æœ€å°å±‚è¿›åº¦", "ä»exit_layer_stats.percentile(0.1)å­¦ä¹ "),
        ("è®¤çŸ¥è´Ÿè·", "ä»(ç½®ä¿¡åº¦, ç†µåˆ†ä½æ•°, å±‚è¿›åº¦)è¿ç»­è®¡ç®—"),
        ("æ¨èæ·±åº¦", "ä»cognitive_loadè¿ç»­æ¨å¯¼"),
    ]
    
    print(f"\n{'å‚æ•°':<15} | {'æ¥æº':<50}")
    print("-" * 70)
    for param, source in checks:
        print(f"{param:<15} | {source:<50}")
    
    print("\néªŒè¯ç»“æœ:")
    print("  âœ… æ‰€æœ‰å†³ç­–è¾¹ç•Œä»åœ¨çº¿ç»Ÿè®¡é‡åŠ¨æ€è®¡ç®—")
    print("  âœ… æ— ä»»ä½•é­”æ³•æ•°å­—æˆ–äººå·¥é˜ˆå€¼")
    print("  âœ… ç³»ç»Ÿåœ¨çƒ­èº«åè‡ªåŠ¨æ ¡å‡†")
    
    return True


def test_continuous_cognitive_load():
    """éªŒè¯è¿ç»­è®¤çŸ¥è´Ÿè·"""
    print("\n" + "=" * 70)
    print("Test 4: Continuous Cognitive Load (è¿ç»­è®¤çŸ¥è´Ÿè·)")
    print("=" * 70)
    
    checkpoint_path = "checkpoints/intuition_network_best_v9.pt"
    if not Path(checkpoint_path).exists():
        checkpoint_path = "checkpoints/intuition_network_best.pt"
    
    engine = create_adaptive_engine(checkpoint_path=checkpoint_path, warmup_steps=10)
    
    # æ”¶é›†cognitive_loadåˆ†å¸ƒ
    loads = []
    
    # å¿«é€Ÿçƒ­èº«
    for _ in range(20):
        hidden = torch.randn(1, 8, device=engine.device)
        engine.step(hidden, 18, 36)
    
    engine.reset()
    
    # æ”¶é›†æ ·æœ¬
    for layer_idx in range(36):
        hidden = torch.randn(1, 8, device=engine.device)
        state = engine.step(hidden, layer_idx, 36)
        loads.append(state.cognitive_load)
    
    # ç»Ÿè®¡
    import numpy as np
    loads = np.array(loads)
    
    print(f"\nCognitive Load åˆ†å¸ƒ:")
    print(f"  èŒƒå›´: [{loads.min():.3f}, {loads.max():.3f}]")
    print(f"  å‡å€¼: {loads.mean():.3f}")
    print(f"  æ ‡å‡†å·®: {loads.std():.3f}")
    print(f"  å”¯ä¸€å€¼æ•°é‡: {len(np.unique(loads.round(3)))}")
    
    # éªŒè¯è¿ç»­æ€§
    is_continuous = len(np.unique(loads.round(3))) > 10  # è‡³å°‘10ä¸ªä¸åŒçš„å€¼
    
    print(f"\néªŒè¯ç»“æœ:")
    print(f"  {'âœ…' if is_continuous else 'âŒ'} è®¤çŸ¥è´Ÿè·ä¸ºè¿ç»­å€¼ (éç¦»æ•£ç­‰çº§)")
    
    return is_continuous


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=" * 70)
    print("SEDAC V9.0 - å…¨è‡ªä¸»ç³»ç»Ÿé›†æˆæµ‹è¯•")
    print("=" * 70)
    print("""
æ ¸å¿ƒéªŒè¯ç›®æ ‡:
1. é›¶ç¡¬ç¼–ç é˜ˆå€¼ - æ‰€æœ‰å†³ç­–ä»æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ 
2. è¿ç»­è®¤çŸ¥è´Ÿè· - ä¸æ˜¯ç¦»æ•£çš„5çº§æ¨¡å¼
3. è‡ªé€‚åº”å¹²é¢„ - æ ¹æ®ç»Ÿè®¡åˆ†å¸ƒåŠ¨æ€è§¦å‘
4. é€€å‡ºç²¾åº¦ >= 95% - é«˜ç²¾åº¦æ—©é€€
""")
    
    results = []
    
    # Test 1: è‡ªé€‚åº”å¼•æ“
    try:
        results.append(("Adaptive Engine", test_adaptive_engine()))
    except Exception as e:
        logger.error(f"Test 1 failed: {e}")
        results.append(("Adaptive Engine", False))
    
    # Test 2: å¹²é¢„æœºåˆ¶
    try:
        results.append(("Intervention", test_intervention_mechanism()))
    except Exception as e:
        logger.error(f"Test 2 failed: {e}")
        results.append(("Intervention", False))
    
    # Test 3: é›¶ç¡¬ç¼–ç 
    try:
        results.append(("No Hardcoded", test_no_hardcoded_values()))
    except Exception as e:
        logger.error(f"Test 3 failed: {e}")
        results.append(("No Hardcoded", False))
    
    # Test 4: è¿ç»­è®¤çŸ¥è´Ÿè·
    try:
        results.append(("Continuous Load", test_continuous_cognitive_load()))
    except Exception as e:
        logger.error(f"Test 4 failed: {e}")
        results.append(("Continuous Load", False))
    
    # æ€»ç»“
    print("\n" + "=" * 70)
    print("Summary (æµ‹è¯•æ€»ç»“)")
    print("=" * 70)
    
    all_passed = True
    for name, passed in results:
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"  {name}: {status}")
        if not passed:
            all_passed = False
    
    print("\n" + "=" * 70)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼SEDAC V9.0 å…¨è‡ªä¸»ç³»ç»ŸéªŒè¯æˆåŠŸï¼")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
    print("=" * 70)
    
    return all_passed


if __name__ == "__main__":
    main()
