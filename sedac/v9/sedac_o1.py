"""
SEDAC-O1: è‡ªé€‚åº”æ€è€ƒæ—¶é—´ (Adaptive Computation Time)

å¯¹æ ‡: OpenAI o1 / DeepSeek-R1

æ ¸å¿ƒç†å¿µ:
- V9.0 SEDAC æ˜¯ä¸ºäº†"çœç®—åŠ›"ï¼ˆåšå‡æ³•ï¼‰
- SEDAC-O1 æ˜¯ä¸ºäº†"å¢æ™ºæ…§"ï¼ˆåšåŠ æ³•ï¼‰

å½“æ£€æµ‹åˆ°æé«˜ç†µï¼ˆæåº¦å›°æƒ‘ï¼‰æ—¶ï¼š
1. ä¸ä»…ä¸è·³å±‚ï¼Œåè€ŒåŠ¨æ€æ’å…¥é¢å¤–çš„"æ€è€ƒToken"
2. å¾ªç¯è°ƒç”¨è®¡ç®—æ¨¡å—ï¼Œç›´åˆ°ç†µé™ä½åˆ°å¯æ¥å—æ°´å¹³
3. å®ç°System 2æ·±åº¦æ¨ç†

è¿™æ˜¯é€šå‘AGIçš„æ ¸å¿ƒ â€”â€” è®©æ¨¡å‹åœ¨éš¾é—®é¢˜ä¸Šè‡ªåŠ¨å±•å¼€æ€ç»´é“¾
"""

from __future__ import annotations
import torch
import torch.nn as nn
import torch.nn.functional as F
from dataclasses import dataclass, field
from typing import Optional, List, Dict, Any, Tuple, Callable
from enum import Enum, auto
import logging
import math

logger = logging.getLogger(__name__)


class ThinkingMode(Enum):
    """æ€è€ƒæ¨¡å¼"""
    FAST = auto()      # System 1: å¿«é€Ÿç›´è§‰å“åº”
    SLOW = auto()      # System 2: æ·±åº¦æ¨ç†
    ADAPTIVE = auto()  # è‡ªé€‚åº”åˆ‡æ¢


@dataclass
class ThinkingState:
    """æ€è€ƒçŠ¶æ€"""
    mode: ThinkingMode
    thinking_depth: int           # å½“å‰æ€è€ƒæ·±åº¦
    max_thinking_depth: int       # æœ€å¤§å…è®¸æ·±åº¦
    accumulated_entropy: float    # ç´¯ç§¯ç†µ
    entropy_trajectory: List[float] = field(default_factory=list)
    thinking_tokens: List[str] = field(default_factory=list)
    confidence_trajectory: List[float] = field(default_factory=list)
    should_continue_thinking: bool = True
    reasoning_complete: bool = False


@dataclass
class ThinkingConfig:
    """æ€è€ƒé…ç½®"""
    # ç†µé˜ˆå€¼
    high_entropy_threshold: float = 4.5      # è§¦å‘æ·±åº¦æ€è€ƒ
    low_entropy_threshold: float = 2.0       # å¯ä»¥åœæ­¢æ€è€ƒ
    
    # æ€è€ƒæ·±åº¦
    max_thinking_steps: int = 8              # æœ€å¤§æ€è€ƒæ­¥æ•°
    min_thinking_steps: int = 1              # æœ€å°æ€è€ƒæ­¥æ•°
    
    # è‡ªé€‚åº”å‚æ•°
    entropy_reduction_target: float = 0.3    # æ¯æ­¥ç†µé™ä½ç›®æ ‡
    confidence_threshold: float = 0.8        # åœæ­¢æ€è€ƒçš„ç½®ä¿¡åº¦
    
    # Tokené¢„ç®—
    max_thinking_tokens: int = 512           # æœ€å¤§æ€è€ƒTokenæ•°
    
    # å­¦ä¹ å‚æ•°
    adaptive_threshold: bool = True          # æ˜¯å¦è‡ªé€‚åº”è°ƒæ•´é˜ˆå€¼


class ThinkingTokenGenerator:
    """
    æ€è€ƒTokenç”Ÿæˆå™¨
    
    åœ¨é«˜ç†µæ—¶ç”Ÿæˆ"æ€è€ƒæç¤º"å¼•å¯¼æ¨¡å‹æ·±å…¥æ¨ç†
    """
    
    # é¢„å®šä¹‰çš„æ€è€ƒæç¤ºæ¨¡æ¿
    THINKING_PROMPTS = {
        "decompose": [
            "Let me break this down step by step.",
            "First, I need to identify the key components.",
            "Let's analyze this systematically.",
        ],
        "verify": [
            "Let me verify this reasoning.",
            "I should double-check this conclusion.",
            "Wait, let me reconsider.",
        ],
        "explore": [
            "What if I approach this differently?",
            "Another way to think about this is...",
            "Consider the alternative perspective:",
        ],
        "synthesize": [
            "Putting it all together...",
            "Based on the above analysis...",
            "Therefore, the conclusion is...",
        ],
    }
    
    def __init__(self, config: ThinkingConfig = None):
        self.config = config or ThinkingConfig()
        self.step_count = 0
    
    def generate_prompt(
        self,
        entropy: float,
        thinking_depth: int,
        entropy_trend: str = "stable",  # "decreasing", "increasing", "stable"
    ) -> str:
        """
        æ ¹æ®å½“å‰çŠ¶æ€ç”Ÿæˆæ€è€ƒæç¤º
        """
        if thinking_depth == 0:
            # å¼€å§‹æ€è€ƒ
            prompts = self.THINKING_PROMPTS["decompose"]
        elif entropy_trend == "increasing":
            # ç†µå¢åŠ ï¼Œéœ€è¦éªŒè¯
            prompts = self.THINKING_PROMPTS["verify"]
        elif thinking_depth >= self.config.max_thinking_steps - 2:
            # æ¥è¿‘ç»“æŸï¼Œéœ€è¦ç»¼åˆ
            prompts = self.THINKING_PROMPTS["synthesize"]
        else:
            # ç»§ç»­æ¢ç´¢
            prompts = self.THINKING_PROMPTS["explore"]
        
        # å¾ªç¯é€‰æ‹©
        prompt = prompts[self.step_count % len(prompts)]
        self.step_count += 1
        
        return prompt
    
    def reset(self):
        """é‡ç½®çŠ¶æ€"""
        self.step_count = 0


class EntropyMonitor:
    """
    ç†µç›‘æ§å™¨
    
    è·Ÿè¸ªç†µçš„å˜åŒ–è¶‹åŠ¿ï¼Œå†³å®šä½•æ—¶å¯åŠ¨/åœæ­¢æ·±åº¦æ€è€ƒ
    """
    
    def __init__(self, window_size: int = 5):
        self.window_size = window_size
        self.history: List[float] = []
        
        # åœ¨çº¿ç»Ÿè®¡é‡
        self.n = 0
        self.mean = 0.0
        self.M2 = 0.0  # ç”¨äºè®¡ç®—æ–¹å·®
    
    def update(self, entropy: float):
        """æ›´æ–°ç†µè§‚æµ‹"""
        self.history.append(entropy)
        if len(self.history) > self.window_size * 2:
            self.history.pop(0)
        
        # Welfordåœ¨çº¿æ›´æ–°
        self.n += 1
        delta = entropy - self.mean
        self.mean += delta / self.n
        delta2 = entropy - self.mean
        self.M2 += delta * delta2
    
    @property
    def std(self) -> float:
        """æ ‡å‡†å·®"""
        if self.n < 2:
            return 1.0
        return math.sqrt(self.M2 / (self.n - 1))
    
    def get_trend(self) -> str:
        """è·å–ç†µè¶‹åŠ¿"""
        if len(self.history) < 3:
            return "stable"
        
        recent = self.history[-3:]
        if recent[-1] < recent[0] * 0.9:
            return "decreasing"
        elif recent[-1] > recent[0] * 1.1:
            return "increasing"
        else:
            return "stable"
    
    def get_percentile(self, entropy: float) -> float:
        """è·å–ç†µçš„ç™¾åˆ†ä½æ•°"""
        if self.n < 10:
            return 0.5
        
        z_score = (entropy - self.mean) / (self.std + 1e-6)
        # è¿‘ä¼¼CDF
        percentile = 0.5 * (1 + math.erf(z_score / math.sqrt(2)))
        return percentile
    
    def should_trigger_thinking(self, entropy: float, threshold_percentile: float = 0.8) -> bool:
        """æ˜¯å¦åº”è¯¥è§¦å‘æ·±åº¦æ€è€ƒ"""
        return self.get_percentile(entropy) > threshold_percentile
    
    def reset(self):
        """é‡ç½®"""
        self.history.clear()


class AdaptiveComputationController:
    """
    è‡ªé€‚åº”è®¡ç®—æ§åˆ¶å™¨
    
    æ ¸å¿ƒç»„ä»¶ï¼Œå†³å®šä½•æ—¶ä»¥åŠå¦‚ä½•è¿›è¡Œæ·±åº¦æ€è€ƒ
    """
    
    def __init__(self, config: ThinkingConfig = None):
        self.config = config or ThinkingConfig()
        self.entropy_monitor = EntropyMonitor()
        self.token_generator = ThinkingTokenGenerator(config)
        
        # å½“å‰æ€è€ƒçŠ¶æ€
        self.current_state: Optional[ThinkingState] = None
        
        # ç»Ÿè®¡
        self.total_tokens = 0
        self.thinking_tokens = 0
        self.thinking_sessions = 0
    
    def should_start_thinking(self, entropy: float, confidence: float) -> bool:
        """
        å†³å®šæ˜¯å¦å¯åŠ¨æ·±åº¦æ€è€ƒ
        """
        # æ›´æ–°ç›‘æ§å™¨
        self.entropy_monitor.update(entropy)
        
        # æ¡ä»¶1: ç†µè¶…è¿‡é«˜é˜ˆå€¼
        if entropy > self.config.high_entropy_threshold:
            return True
        
        # æ¡ä»¶2: ç†µå¤„äºå†å²é«˜ä½ï¼ˆè‡ªé€‚åº”ï¼‰
        if self.config.adaptive_threshold:
            if self.entropy_monitor.should_trigger_thinking(entropy, 0.85):
                return True
        
        # æ¡ä»¶3: ç½®ä¿¡åº¦æä½
        if confidence < 0.2:
            return True
        
        return False
    
    def should_continue_thinking(self, state: ThinkingState) -> bool:
        """
        å†³å®šæ˜¯å¦ç»§ç»­æ€è€ƒ
        """
        # å·²è¾¾åˆ°æœ€å¤§æ·±åº¦
        if state.thinking_depth >= state.max_thinking_depth:
            return False
        
        # ç†µå·²ç»é™ä½åˆ°å¯æ¥å—æ°´å¹³
        if state.entropy_trajectory and state.entropy_trajectory[-1] < self.config.low_entropy_threshold:
            return False
        
        # ç½®ä¿¡åº¦å·²ç»è¶³å¤Ÿé«˜
        if state.confidence_trajectory and state.confidence_trajectory[-1] > self.config.confidence_threshold:
            return False
        
        # ç†µåœ¨æŒç»­å¢åŠ ï¼ˆæ€è€ƒæ— æ•ˆï¼‰
        if len(state.entropy_trajectory) >= 3:
            if all(state.entropy_trajectory[i] < state.entropy_trajectory[i+1] 
                   for i in range(-3, -1)):
                return False
        
        return True
    
    def start_thinking(self, entropy: float, confidence: float) -> ThinkingState:
        """
        å¯åŠ¨æ·±åº¦æ€è€ƒ
        """
        self.thinking_sessions += 1
        
        # æ ¹æ®åˆå§‹ç†µä¼°è®¡éœ€è¦çš„æ€è€ƒæ·±åº¦
        entropy_excess = entropy - self.config.low_entropy_threshold
        estimated_steps = min(
            self.config.max_thinking_steps,
            max(self.config.min_thinking_steps, int(entropy_excess / self.config.entropy_reduction_target))
        )
        
        state = ThinkingState(
            mode=ThinkingMode.SLOW,
            thinking_depth=0,
            max_thinking_depth=estimated_steps,
            accumulated_entropy=entropy,
            entropy_trajectory=[entropy],
            confidence_trajectory=[confidence],
            should_continue_thinking=True,
            reasoning_complete=False,
        )
        
        self.current_state = state
        self.token_generator.reset()
        
        logger.debug(f"Started thinking session: entropy={entropy:.2f}, estimated_steps={estimated_steps}")
        
        return state
    
    def step(
        self,
        entropy: float,
        confidence: float,
        hidden_states: Optional[torch.Tensor] = None,
    ) -> Tuple[ThinkingState, Optional[str]]:
        """
        æ‰§è¡Œä¸€æ­¥æ€è€ƒ
        
        Returns:
            (updated_state, thinking_prompt or None)
        """
        if self.current_state is None:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¯åŠ¨æ€è€ƒ
            if self.should_start_thinking(entropy, confidence):
                state = self.start_thinking(entropy, confidence)
                prompt = self.token_generator.generate_prompt(
                    entropy, 
                    state.thinking_depth,
                    self.entropy_monitor.get_trend()
                )
                return state, prompt
            else:
                # å¿«é€Ÿæ¨¡å¼ï¼Œä¸éœ€è¦æ€è€ƒ
                return ThinkingState(
                    mode=ThinkingMode.FAST,
                    thinking_depth=0,
                    max_thinking_depth=0,
                    accumulated_entropy=entropy,
                    should_continue_thinking=False,
                    reasoning_complete=True,
                ), None
        
        # å·²åœ¨æ€è€ƒä¸­
        state = self.current_state
        state.thinking_depth += 1
        state.entropy_trajectory.append(entropy)
        state.confidence_trajectory.append(confidence)
        state.accumulated_entropy += entropy
        
        self.thinking_tokens += 1
        
        # æ£€æŸ¥æ˜¯å¦ç»§ç»­
        if not self.should_continue_thinking(state):
            state.should_continue_thinking = False
            state.reasoning_complete = True
            self.current_state = None
            return state, None
        
        # ç”Ÿæˆä¸‹ä¸€ä¸ªæ€è€ƒæç¤º
        prompt = self.token_generator.generate_prompt(
            entropy,
            state.thinking_depth,
            self.entropy_monitor.get_trend()
        )
        state.thinking_tokens.append(prompt)
        
        return state, prompt
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_tokens": self.total_tokens,
            "thinking_tokens": self.thinking_tokens,
            "thinking_sessions": self.thinking_sessions,
            "thinking_ratio": self.thinking_tokens / max(self.total_tokens, 1),
            "avg_thinking_depth": self.thinking_tokens / max(self.thinking_sessions, 1),
        }
    
    def reset(self):
        """é‡ç½®çŠ¶æ€"""
        self.current_state = None
        self.entropy_monitor.reset()
        self.token_generator.reset()


class SEDACO1Engine:
    """
    SEDAC-O1 å¼•æ“
    
    ç»“åˆV9.0çš„æ—©é€€èƒ½åŠ›å’ŒO1çš„æ·±åº¦æ€è€ƒèƒ½åŠ›
    """
    
    def __init__(
        self,
        config: ThinkingConfig = None,
        device: torch.device = None,
    ):
        self.config = config or ThinkingConfig()
        self.device = device or torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        self.controller = AdaptiveComputationController(config)
        
        # æ¨¡å¼ç»Ÿè®¡
        self.fast_count = 0
        self.slow_count = 0
    
    def process(
        self,
        entropy: float,
        confidence: float,
        hidden_states: Optional[torch.Tensor] = None,
    ) -> Tuple[ThinkingMode, Optional[str], Dict[str, Any]]:
        """
        å¤„ç†å•ä¸ªToken
        
        Returns:
            (mode, thinking_prompt, metadata)
        """
        self.controller.total_tokens += 1
        
        state, prompt = self.controller.step(entropy, confidence, hidden_states)
        
        if state.mode == ThinkingMode.FAST:
            self.fast_count += 1
        else:
            self.slow_count += 1
        
        metadata = {
            "thinking_depth": state.thinking_depth,
            "accumulated_entropy": state.accumulated_entropy,
            "should_continue": state.should_continue_thinking,
            "reasoning_complete": state.reasoning_complete,
        }
        
        return state.mode, prompt, metadata
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡"""
        total = self.fast_count + self.slow_count
        return {
            "fast_mode_ratio": self.fast_count / max(total, 1),
            "slow_mode_ratio": self.slow_count / max(total, 1),
            **self.controller.get_statistics(),
        }
    
    def reset(self):
        """é‡ç½®"""
        self.controller.reset()
        self.fast_count = 0
        self.slow_count = 0


class ThinkingTokenEmbedder(nn.Module):
    """
    æ€è€ƒTokenåµŒå…¥å™¨
    
    å°†æ€è€ƒæç¤ºè½¬æ¢ä¸ºå¯ä»¥æ³¨å…¥æ¨¡å‹çš„åµŒå…¥
    """
    
    def __init__(
        self,
        hidden_size: int = 4096,
        num_thinking_types: int = 4,  # decompose, verify, explore, synthesize
    ):
        super().__init__()
        self.hidden_size = hidden_size
        
        # æ€è€ƒç±»å‹åµŒå…¥
        self.type_embeddings = nn.Embedding(num_thinking_types, hidden_size)
        
        # æ·±åº¦ä½ç½®åµŒå…¥
        self.depth_projection = nn.Linear(1, hidden_size)
        
        # èåˆå±‚
        self.fusion = nn.Linear(hidden_size * 2, hidden_size)
    
    def forward(
        self,
        thinking_type: int,
        thinking_depth: int,
        max_depth: int = 8,
    ) -> torch.Tensor:
        """
        ç”Ÿæˆæ€è€ƒTokenåµŒå…¥
        
        Returns:
            embedding: [1, hidden_size]
        """
        # ç±»å‹åµŒå…¥
        type_idx = torch.tensor([thinking_type], device=self.type_embeddings.weight.device)
        type_emb = self.type_embeddings(type_idx)
        
        # æ·±åº¦åµŒå…¥
        depth_normalized = torch.tensor([[thinking_depth / max_depth]], 
                                        device=self.type_embeddings.weight.device,
                                        dtype=torch.float32)
        depth_emb = self.depth_projection(depth_normalized)
        
        # èåˆ
        combined = torch.cat([type_emb, depth_emb], dim=-1)
        output = self.fusion(combined)
        
        return output


def create_sedac_o1_engine(config: ThinkingConfig = None) -> SEDACO1Engine:
    """åˆ›å»ºSEDAC-O1å¼•æ“"""
    return SEDACO1Engine(config)


def demo_sedac_o1():
    """æ¼”ç¤ºSEDAC-O1"""
    import random
    
    print("=" * 60)
    print("SEDAC-O1 Demo: Adaptive Computation Time")
    print("=" * 60)
    
    engine = create_sedac_o1_engine()
    
    # æ¨¡æ‹Ÿä¸åŒéš¾åº¦çš„é—®é¢˜
    scenarios = [
        ("ç®€å•äº‹å®é—®ç­”", [(1.5, 0.9), (1.2, 0.95)]),  # ä½ç†µï¼Œé«˜ç½®ä¿¡
        ("ä¸­ç­‰æ¨ç†", [(3.0, 0.6), (2.5, 0.7), (2.0, 0.8)]),  # ä¸­ç†µ
        ("å¤æ‚æ•°å­¦è¯æ˜", [(5.0, 0.2), (4.5, 0.3), (4.0, 0.4), (3.5, 0.5), (3.0, 0.7), (2.5, 0.85)]),  # é«˜ç†µï¼Œéœ€è¦æ·±åº¦æ€è€ƒ
    ]
    
    for scenario_name, entropy_confidence_pairs in scenarios:
        print(f"\n{'='*40}")
        print(f"åœºæ™¯: {scenario_name}")
        print(f"{'='*40}")
        
        engine.reset()
        
        for i, (entropy, confidence) in enumerate(entropy_confidence_pairs):
            mode, prompt, metadata = engine.process(entropy, confidence)
            
            mode_str = "ğŸƒ FAST" if mode == ThinkingMode.FAST else "ğŸ¤” SLOW"
            print(f"  Step {i+1}: entropy={entropy:.2f}, conf={confidence:.2f} â†’ {mode_str}")
            
            if prompt:
                print(f"    ğŸ’­ {prompt}")
            
            if metadata["reasoning_complete"]:
                print(f"    âœ… æ¨ç†å®Œæˆ (depth={metadata['thinking_depth']})")
        
        stats = engine.get_statistics()
        print(f"\n  ç»Ÿè®¡: Fast={stats['fast_mode_ratio']*100:.1f}%, Slow={stats['slow_mode_ratio']*100:.1f}%")
    
    print("\n" + "=" * 60)
    print("SEDAC-O1: ç®€å•é—®é¢˜å¿«é€Ÿå›ç­”ï¼Œå¤æ‚é—®é¢˜æ·±åº¦æ€è€ƒ")
    print("=" * 60)


if __name__ == "__main__":
    demo_sedac_o1()
